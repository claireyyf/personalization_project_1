{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: csv_file is not included in the repo\n",
    "\n",
    "def get_sample(csv_file, N, seed):\n",
    "    np.random.seed(seed)\n",
    "    ratings = pd.read_csv(csv_file)\n",
    "    \n",
    "    #keep only ratings from the most recent 5 yearsï¼š 2010-2015\n",
    "    ratings['year'] = ratings['timestamp'].apply(lambda x: date.fromtimestamp(x).year)\n",
    "    ratings = ratings[ratings['year']>=date.fromisoformat('2010-01-01').year]\n",
    "    ratings.drop(['timestamp','year'],axis=1,inplace=True) #'timestamp' and 'year' no longer useful \n",
    "    \n",
    "    #keep only movies with at least 20 ratings\n",
    "    m_counts = ratings.groupby('movieId').size()\n",
    "    m_index = m_counts[m_counts>=20].index\n",
    "    ratings = ratings[ratings['movieId'].isin(m_index)]\n",
    "    \n",
    "    #keep only users who have rated at least 20 movies - consistent with original data\n",
    "    u_counts = ratings.groupby('userId').size()\n",
    "    u_index = u_counts[u_counts>=20].index\n",
    "    ratings = ratings[ratings['userId'].isin(u_index)]\n",
    "    \n",
    "    #sample out N users\n",
    "    users = np.unique(ratings['userId'])\n",
    "    u_index_sample = np.random.choice(users, N)\n",
    "    sample = ratings[ratings['userId'].isin(u_index_sample)]\n",
    "    \n",
    "    #keep a percentage of ratings for each user: 30% -- lower variance\n",
    "    pct = pd.DataFrame(columns=['userId','movieId','rating'])\n",
    "    u_N, u_rating_count = np.unique(sample['userId'], return_counts=True)\n",
    "    \n",
    "    for i in range(len(u_N)):\n",
    "        u_id = u_N[i]\n",
    "        u_sample = sample[sample['userId']==u_id]\n",
    "        u_sample = u_sample[u_sample['movieId'].isin(np.random.choice(np.unique(u_sample['movieId']),\n",
    "                                                                      int(u_rating_count[i]*0.3)))]\n",
    "        pct = pct.append(u_sample)\n",
    "    \n",
    "    sample = pct\n",
    "    \n",
    "#     #plot data\n",
    "#     users_s, u_count_s = np.unique(sample['userId'], return_counts=True)\n",
    "#     plt.plot(np.arange(1, len(users_s)+1), sorted(sample.groupby('userId').size(), reverse=True))\n",
    "#     plt.xlabel('number of users')\n",
    "#     plt.ylabel('number of rated movies')\n",
    "#     plt.show()\n",
    "    \n",
    "    print('number of unique users:', len(np.unique(sample['userId'])))\n",
    "    print('number of unique movies:', len(np.unique(sample['movieId'])))\n",
    "    \n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(sample_data, split, seed):\n",
    "    np.random.seed(seed)\n",
    "    sample = sample_data\n",
    "    \n",
    "    train, test = train_test_split(sample, test_size=split)\n",
    "    \n",
    "    #check\n",
    "    print('number of users in train:',len(np.unique(train['userId'])))\n",
    "    print('number of movies in train:',len(np.unique(train['movieId'])))\n",
    "    print('number of users in test:', len(np.unique(test['userId'])))\n",
    "    print('number of movies in test:',len(np.unique(test['movieId'])))\n",
    "    \n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users: 974\n",
      "number of unique movies: 5619\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample('ratings.csv', 1000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameter\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "data = Dataset.load_from_df(sample[['userId','movieId','rating']], reader)\n",
    "\n",
    "train, test = train_test_split(data, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8700131439977484"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "algo = BaselineOnly()\n",
    "algo.fit(train)\n",
    "predictions = algo.test(test)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.014822991493837"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN Basic\n",
    "from surprise import KNNBasic\n",
    "\n",
    "algo = KNNBasic()\n",
    "algo.fit(train)\n",
    "predictions = algo.test(test)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9356376753748737"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN adjusted for Z-Score\n",
    "from surprise import KNNWithZScore\n",
    "\n",
    "algo = KNNWithZScore()\n",
    "algo.fit(train)\n",
    "predictions = algo.test(test)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.921254895302728"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN Adjusted for Baseline\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "algo = KNNBaseline()\n",
    "algo.fit(train)\n",
    "predictions = algo.test(test)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
